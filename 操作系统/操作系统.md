# 操作系统

[TOC]



## 1. 为什么需要操作系统

- 操作系统类似于一个协调者，它提供了一套接口和标准来抹平不同硬件的差异，这样只要操作系统一样，硬件能达到软件运行的最低标准，那么软件就可以运行，不需要考虑硬件的差异
- 同时，操作系统为所有程序分配资源，一切程序都要听从操作系统的调度，当它们需要访问资源时需要向操作系统申请权限由操作系统进行资源的分配，这样可以最大程序利用计算机资源的同时让各个程序互不冲突
- 操作系统屏蔽了底层硬件调度的细节，为应用程序提供基础，担当计算机用户和计算机硬件的中介，减少开发人员的开发难度，让非技术人员也能使用计算机系统
- 操作系统提供了便利，高效的使用体验



## 2. System/Application Programs

操作系统包含系统或应用程序

- 系统程序：

系统程序是用于直接命令或修改计算机硬件的软件

- 应用程序：

应用程序是用于执行特定任务，可供用户直接使用的程序或软件（比如office， 编译器，网页浏览器等）



## 3. 引导程序（Bootstrap Program）

电脑启动或重新运行时执行的第一个程序。引导程序存储于ROM(Read Only Memory)中，它必须知道如何加载操作系统并开始执行系统，它必须定位操作系统内核并将其加载到内存中



## 4. 中断（Interrupt）



**重要：没有中断技术就无法实现多段进程并发执行，中断可以让操作系统内核强行夺回CPU控制权**



![image-20240328192247110](Images\image-20240328192247110.png)

- **来源**：中断通常来源于硬件设备，如I/O操作完成、定时器溢出等。也可以由软件生成，称为软中断或软件中断。
- **异步性**：中断是异步发生的，与CPU的当前执行流程无关。
- **目的**：中断的主要目的是响应外部事件或内部事件，允许操作系统对这些事件进行处理，如处理硬件请求、执行定时任务等。
- **处理**：中断会导致当前执行流程被打断，操作系统保存当前的上下文（程序计数器、寄存器等），转而执行与中断对应的中断服务例程（ISR）。ISR执行完毕后，系统恢复被中断的任务。



一个事件的发生通常由从硬件或软件的中断发出信号，在CPU做某项工作时，有时硬件或软件可能会中断CPU正在执行的工作，并让它执行另一个工作，执行完成后回到当前工作继续执行，硬件通常使用系统总线向CPU发送信号来触发中断



中断处理通常涉及以下步骤：

1. **中断触发**：硬件设备向处理器发送中断信号。
2. **中断响应**：当前执行被暂停，处理器保存当前的上下文（如程序计数器、寄存器等）。
3. **执行中断服务例程（ISR）**：根据中断向量表找到对应的中断服务例程并执行。中断向量表是一个函数指针数组，每个元素指向一个ISR。
4. **中断返回**：ISR执行完成后，处理器恢复之前保存的上下文，并继续执行被中断的任务。

![image-20240328203642416](Images\image-20240328203642416.png)

### 4.1 内中断（也叫做异常）

与当前执行的指令**有关**，中断信号来自于CPU**内部**

![image-20240328193207708](Images\image-20240328193207708.png)

![image-20240328193307053](Images\image-20240328193307053.png)

分为三种：

- **陷阱、陷入（trap）**

​	由陷入指令（比如断点）引发，是应用程序故意引发的，要注意陷入指令**不是特权指令**

- **故障（fault）**

​	由错误条件引起的，可能被内核程序修复。内核程序修复故障后会把CPU使用权交给应用程序让它继续执行下去，比如：**缺页故障**

- **终止（abort）**

​	由致命错误引起，内核程序无法修复该错误，因此一般不再将使用权还给引发终止的应用程序，而是直接终止该应用程序。如：整数除0，非法使用特权指令

### 4.2 外中断

与当前执行的指令**无关**，中断信号来自于CPU**外部**

![image-20240328194109230](Images\image-20240328194109230.png)

### 4.3 系统调用

软件可以通过执行称为系统调用的特殊操作来触发中断

![image-20240328204041660](Images\image-20240328204041660.png)

![image-20240328204125690](Images\image-20240328204125690.png)

![image-20240328204324480](Images\image-20240328204324480.png)

系统调用协调分配资源防止出现意想不到的情况

### 4.4 CPU响应

当CPU被中断时会停止执行当前任务并立即将执行转移到固定位置（通常是中断服务程序的起始地址），每一个中断都有一个中断服务程序，当CPU执行完中断服务程序后会回到之前执行的任务继续执行



## 5. 进程

被加载到内存中执行的程序被称为“进程”

![image-20240328205819745](Images\image-20240328205819745.png)

### 5.1 进程状态

- #### 新建（New）

​	这是进程刚被创建时的状态。在这个状态下，操作系统为进程分配了必要的资源，例如内存空间、进程控制块（PCB）等。一旦分配完成，进程就可以转移到就绪状态。

- #### 就绪（Ready）

​	进程已准备好运行，并等待CPU时间。在这个状态下，进程已经拥有除CPU之外的所有必要资源，它被放在就绪队列中，等待操作系统的调度程序（Scheduler）将其选中并分配CPU时间片，以便执行。

- #### 运行（Running）

​	进程正在CPU上执行。一个进程在任意时刻只能在一个CPU上运行。当进程获得CPU时间后，它可以执行指令、进行计算等。运行状态的进程可能由于时间片用完、等待I/O操作或其他资源而转换到其他状态。

- #### 等待（Waiting 或 Blocked）

​	进程因为等待某种条件（如I/O操作完成、获取某种锁资源等）而暂停执行。在这个状态下，即使CPU空闲，进程也无法执行，直到其等待的条件得到满足。满足条件后，进程通常会转移到就绪状态，等待重新获得CPU时间。

- #### 终止（Terminated 或 Exit）

​	进程完成执行或者被操作系统终止。在这个状态下，进程的所有资源，包括打开的文件、占用的内存等，都会被操作系统回收。进程的PCB会保留一些终止信息直到操作系统处理完毕，之后也会被删除。

****

- #### 进程状态转换

进程在其生命周期中会经历多种状态，状态之间的转换通常由操作系统事件（如时间片用尽、I/O请求完成等）触发。这些状态转换反映了进程对系统资源的需求以及操作系统对资源的调度策略。

- #### 可选状态

除了上述基本状态外，一些系统可能还支持其他进程状态，例如：

**挂起就绪（Suspended Ready）**：进程已经准备好运行，但被移到外部存储，这通常发生在系统需要为其他进程释放内存时。

**挂起等待（Suspended Blocked）**：进程因等待某些条件而被挂起，通常是因为系统资源紧张。



### 5.2 PCB(Process Control Block)

每个进程在操作系统中都由一个进程控制块表示，简称PCB

- ### **`PCB主要包含以下信息：`**

1. **进程标识符（PID）**：每个进程的唯一标识。系统可以通过PID来区分不同的进程。
2. **用户ID（UID）**：进程所属用户ID
3. **进程状态**：进程当前的状态，如就绪（Ready）、运行（Running）、等待（Waiting）或终止（Terminated）等。
4. **程序计数器（PC）**：指向进程将要执行的**下一条指令的地址**。程序计数器使得操作系统能够在进程被中断后恢复执行。
5. **CPU寄存器信息**：保存进程执行状态的寄存器集，包括累加器、索引寄存器、栈指针等。当进程被中断时，其寄存器状态会被保存到PCB中，以便进程恢复执行时能够恢复这些值。
6. **CPU调度信息**：包括进程优先级、调度队列指针、调度参数等，这些信息用于进程调度决策。
7. **内存管理信息**：包括进程的地址空间信息，如页表、段表等，用于虚拟内存管理和物理地址映射。
8. **账户信息**：记录进程使用的CPU时间、实际使用时间等，用于统计、限制和计费等。
9. **I/O状态信息**：包括分配给进程的I/O设备列表、打开文件的列表等。这些信息用于管理进程的输入输出操作。

- ### `PCB的作用`

- **进程管理**：PCB是操作系统管理进程生命周期的基础。通过PCB，操作系统能够创建、调度、中断和终止进程。
- **进程切换**：在进行进程切换时，操作系统会保存当前进程的状态到其PCB中，并从另一个进程的PCB中恢复其状态，以实现多任务。
- **资源管理**：PCB帮助操作系统跟踪每个进程使用的资源，如内存、文件和I/O设备，确保资源正确分配和回收。
- **同步与通信**：PCB中的信息可以用于进程同步和通信机制，如信号量、消息队列等。



### 5.3 进程调度算法

- #### 先来先服务（FCFS, First-Come, First-Served）

**非抢占式**

这是最简单的调度算法。进程按照它们到达就绪队列的顺序被调度。一旦一个进程开始执行，它会持续运行，直到完成。FCFS的主要问题是平均等待时间可能很长，特别是当长进程运行在短进程之前时。

- #### 短作业优先（SJF, Shortest Job First）

**非抢占式**

在这个算法中，具有最短执行时间的进程首先获得CPU。这种非抢占式调度可以最小化平均等待时间。然而，它的主要问题是饥饿（长作业可能永远得不到调度），以及需要提前知道进程的执行时间。

- #### 最短剩余时间优先（SRTF, Shortest Remaining Time First）

**抢占式**

这是SJF的抢占式版本。如果一个新进程到达就绪队列，其预计执行时间小于当前运行进程的剩余时间，调度器会中断当前进程并将CPU分配给新进程。这种方法减少了等待时间，但也增加了上下文切换的次数。

- #### 时间片轮转（RR, Round Robin）

**抢占式**

RR调度算法将CPU时间分成固定长度的片段，称为时间片，然后将它们分配给就绪队列中的每个进程。每个进程运行一个时间片的长度。如果进程在时间片结束时尚未完成，它会被放回就绪队列的末尾。这种方法提高了响应性，但较短的时间片会导致较高的上下文切换开销。

- #### 优先级调度

在优先级调度算法中，每个进程都有一个优先级，调度器根据这些优先级分配CPU时间。具有最高优先级的进程首先获得CPU。**优先级调度可以是非抢占式的或抢占式的**（即一个更高优先级的进程到来时，可以中断当前进程）。这种方法的问题在于较低优先级的进程可能遭受**饥饿**。

- #### 多级反馈队列（MFQ, Multilevel Feedback Queue）

多级反馈队列是一种复杂的调度算法，它设有多个就绪队列，每个队列具有不同的优先级，同样**可以是非抢占式的或抢占式的**。进程根据其属性（如CPU使用时间、进程优先级等）被分配到不同的队列中。调度器首先考虑最高优先级的队列。MFQ旨在提供良好的响应时间，同时考虑到CPU利用率和吞吐量，但它的实现相对复杂。会导致**饥饿**

![image-20240328215840933](Images\image-20240328215840933.png)

![image-20240328220208646](Images\image-20240328220208646.png)



- #### **多级队列调度算法**

![image-20240328220413866](Images\image-20240328220413866.png)

****



![image-20240328214630004](Images\image-20240328214630004.png)



### 5.4 上下文切换

进程的上下文切换是指操作系统在切换从一个进程到另一个进程执行时所进行的一系列操作。这个过程涉及保存当前进程的状态（上下文）并恢复另一个进程的状态，以便新的进程可以从它上次停止的地方继续执行。

- #### `上下文的内容`

进程的上下文主要包括：

- **CPU寄存器状态**：包括通用寄存器、程序计数器（PC）、栈指针（SP）和状态寄存器等。
- **程序计数器**：指向进程将要执行的下一条指令的内存地址。
- **进程状态信息**：如进程的优先级、调度状态和进程ID等。
- **内存管理信息**：如页表、内存分配的状态等。
- **开放文件和I/O状态信息**：如文件描述符、I/O缓冲区等。

- #### `上下文切换的触发`

上下文切换可能由以下几种原因触发：

- **时间片用尽**：在基于时间片的调度算法中，当当前进程的时间片用尽时，操作系统会触发上下文切换。
- **I/O请求**：当进程进行I/O操作而被阻塞时，操作系统会切换到另一个进程。
- **高优先级进程就绪**：当一个高优先级的进程变为就绪状态时，操作系统可能会抢占当前运行的进程，进行上下文切换。
- **等待系统资源**：如信号量、互斥锁等。

- #### `上下文切换的过程`

1. **中断或系统调用**：上下文切换首先由系统调用、中断或异常触发。
2. **保存当前进程上下文**：操作系统保存当前进程的CPU寄存器和其他关键状态到其进程控制块（PCB）。
3. **选择新的进程**：调度器选择另一个进程执行。
4. **恢复新进程上下文**：操作系统从新选定的进程的PCB中恢复CPU寄存器和其他关键状态。
5. **执行新进程**：新的进程开始执行。

- #### `上下文切换的代价`

上下文切换是有代价的，包括：

- **时间开销**：保存和恢复进程状态需要时间，**这期间CPU不做任何有用的工作**。
- **缓存冷却**：新的进程可能会有不同的内存访问模式，导致CPU缓存的数据被替换，从而降低缓存的命中率。

- #### `优化上下文切换`

- **减少不必要的上下文切换**：通过优化调度策略，减少不必要的上下文切换。
- **使用线程**：线程间的上下文切换代价通常低于进程间的切换，因为线程共享同一地址空间和资源。



### 5.5 子进程

- #### `子进程的创建`

子进程通常通过特定的系统调用创建，如UNIX和Linux中的`fork()`，Windows中的`CreateProcess()`等。这些调用创建一个新的进程，该进程几乎是父进程的副本：

- **UNIX/Linux的`fork()`**：`fork()`调用创建一个新进程，该进程是调用进程的副本。新进程（子进程）从`fork()`调用之后的点开始执行，拥有与父进程几乎相同的内存映像，但有其自己的地址空间。
- **执行新程序**：子进程通常会使用如`exec()`系列函数（在UNIX/Linux中）来执行一个新的程序。`exec()`函数替换当前进程的内存空间，包括代码和数据，用新程序的代码和数据。

****

- #### `子进程的特性`

- **独立执行**：子进程拥有独立的地址空间，父进程和子进程的运行互不干扰。子进程的任何数据修改都不会影响父进程，反之亦然。
- **资源共享**：虽然子进程拥有独立的地址空间，但在某些操作系统中，子进程在创建时会继承父进程的资源，如打开的文件描述符（UNIX/Linux）。
- **通信**：子进程可以通过管道、信号、共享内存、消息队列等机制与父进程或其他进程通信。
- **同步**：父进程可以通过特定的系统调用（如`wait()`）等待子进程结束，这在父进程需要子进程完成某些任务后再继续执行时非常有用。

****

- #### `子进程的用途`

- **并行处理**：子进程可以用来并行执行多个任务，提高应用程序的性能。
- **简化编程模型**：通过将复杂任务分解为多个简单的子任务，并为每个子任务创建一个子进程，可以简化编程模型。
- **隔离**：子进程提供了一种隔离机制，使得不同任务在不同的进程空间中运行，增加了系统的稳定性和安全性。

****

- #### `注意事项`

- **资源管理**：大量使用子进程可能会导致资源（如内存和处理器）的过度使用，因此需要谨慎管理。
- **僵尸进程**：如果父进程没有通过`wait()`（或相关函数）等待子进程结束，子进程在结束时可能会成为僵尸进程，占用系统资源。
- **孤儿进程**：如果父进程在子进程之前结束，子进程将成为孤儿进程。在大多数系统中，孤儿进程会被init进程（或类似的进程）接管。

子进程是操作系统进程管理和并发编程中的一个重要概念，通过合理使用子进程，可以设计出高效、模块化和易于管理的应用程序。



### 5.6 僵尸进程

僵尸进程是已经完成执行但仍然在操作系统进程表中占据一个条目的进程。这种情况发生在子进程已经结束，但其父进程尚未通过调用`wait()`或`waitpid()`系统调用来回收子进程的状态信息时。僵尸进程不执行任何代码，也不消耗除了进程表条目之外的任何资源，但它们会占用有限的系统资源——进程号（PID），因此系统上不能有无限多的僵尸进程。

****

- ### 僵尸进程的产生

****

当子进程结束执行时，它会释放占用的大部分资源（如内存和打开的文件），但在操作系统的进程表中仍然保留一个条目，该条目包含了**进程的退出状态及其他一些终止信息**。操作系统保留这些信息是为了让父进程在稍后能够查询子进程的终止状态。如果父进程没有调用`wait()`或`waitpid()`来查询这些信息，子进程的进程表条目就不会被释放，从而导致僵尸进程的出现。



****

- ### 僵尸进程的问题

****

虽然单个僵尸进程消耗的资源非常少，但它们会占用进程号。在UNIX和Linux系统中，进程号是有限的，如果大量僵尸进程累积，可能会耗尽可用的进程号，导致系统无法启动新的进程。



****

- ### 如何处理僵尸进程

****

1. **父进程调用`wait()`或`waitpid()`**：这是预防和处理僵尸进程的最直接方法。这些系统调用使父进程暂停执行，直到它的一个或多个子进程结束，然后回收子进程的状态信息，释放进程表条目。
2. **使用信号**：父进程可以为`SIGCHLD`信号安装一个处理函数，该信号在子进程结束时由操作系统发送给父进程。在信号处理函数中，父进程可以调用`wait()`来回收子进程的状态信息。
3. **父进程结束**：如果僵尸进程的父进程结束，所有剩余的僵尸子进程将被init进程（**PID为1的进程**）领养，**init进程会定期调用`wait()`来回收任何僵尸进程的状态信息**。
4. **避免创建子进程**：在某些情况下，可以通过使用其他并发编程模型（如线程）来避免创建子进程，从而避免僵尸进程的问题。



### 5.7 孤儿进程

孤儿进程是指父进程结束或终止之后仍在运行的子进程。在父进程终止后，没有被终止的子进程将被init进程（在UNIX和Linux系统中，其进程ID通常为1）接管。init进程会定期执行`wait()`系统调用来回收孤儿进程的状态信息，从而防止孤儿进程成为僵尸进程。

****

- ### 孤儿进程的产生

****

- 当一个进程终止时，它的所有子进程将由init进程领养，这些子进程因此成为孤儿进程。这通常发生在父进程因为某种原因提前结束，而子进程还在后台运行时。
- 如果一个子进程是由一个已经终止的父进程创建的，但这个子进程还没有结束，那么这个子进程就变成了孤儿进程。

****

- ### 孤儿进程的处理

****

- 在UNIX和Linux系统中，init进程负责领养孤儿进程。init进程会定期执行`wait()`系统调用来等待孤儿进程结束，并回收它们的资源和状态信息。这样做是为了确保没有进程能永远处于未回收的状态，防止资源泄露。
- 孤儿进程通常不会对系统性能产生负面影响，因为它们仍然可以像正常进程一样运行。一旦它们结束执行，init进程将回收它们所占用的资源。

****

- ### 孤儿进程与僵尸进程的区别

****

- 孤儿进程和僵尸进程都是在特定条件下出现的进程状态，但它们之间有本质的区别。孤儿进程是已经失去父进程的子进程，但它仍然在运行并消耗资源；而僵尸进程是已经结束但其状态信息还未被父进程回收的进程，它不执行任何操作，不消耗除了进程表项之外的任何资源。
- 孤儿进程会被init进程领养，并在执行完成后由init进程清理；僵尸进程则需要其原父进程（或在某些系统中可能是init进程）通过调用`wait()`或`waitpid()`来回收其资源。



### 5.8 进程间通信（IPC）

进程间通信（Inter-Process Communication, IPC）是指在不同进程之间传递数据或信号的机制。由于每个进程在现代操作系统中一般都运行在独立的地址空间中，它们无法直接访问对方的变量或数据结构。因此，操作系统提供了多种IPC机制来实现进程间的数据交换和同步。

****

- ### **为什么需要进程间通信**

****

- ####  **资源共享**

在多个进程需要访问相同的资源（如文件、数据库或内存中的数据结构）时，IPC 提供了一种协调机制，确保资源访问的正确性和一致性。没有适当的同步和通信机制，可能会导致数据损坏或不一致。

- #### 计算分工

在一些复杂的应用中，不同的任务可能被分配给不同的进程，这些进程可能运行在同一台机器上或分布在网络中的不同机器上。IPC 允许这些进程彼此通信，协调工作流程，使得任务能够高效地分工合作完成。

- #### 模块化和解耦

通过IPC，系统可以被设计成多个独立的模块或服务，每个模块或服务运行在其自己的进程中。这种模块化设计使得系统更易于理解、开发和维护，同时也提高了系统的可扩展性和可靠性。

- #### 并发性

IPC 支持系统并发执行多个任务，提高资源利用率和系统吞吐量。通过在多个进程间分配工作，可以利用多核处理器的并行计算能力，从而提升性能。

- #### 安全和隔离

不同进程在操作系统层面上是隔离的，它们拥有独立的地址空间。这种隔离提供了一定程度的安全保护，因为一个进程无法直接访问另一个进程的内存空间。IPC 提供了一种安全的方式，允许这些隔离的进程按需共享数据。

- #### 灵活性和可扩展性

IPC 机制使得在不同机器上运行的进程之间的通信成为可能，这对于构建分布式系统和微服务架构非常重要。这些系统能够通过网络进行通信，从而实现更高的灵活性和可扩展性。



### 5.9 进程间通信的方法

- #### 信号 (Signals)

一种比较简单的通信方式，用于告知接收进程某个事件已经发生。信号是一种软件中断，用于处理异步事件。



#### 5.9.1 共享内存（共享存储）

共享内存是一种高效的进程间通信（IPC）机制，它允许两个或多个进程共享一个给定的内存区域。由于它直接在进程间共享数据，而不是通过操作系统交换数据，因此共享内存通常被认为是最快的IPC方法之一。

该机制可使不同的进程共享主存中的某一个区域，且使该区域出现（映射）在多个进程的虚地址空间中。另一方面，一个进程的虚地址空间中又可连接多个共享存储区，每个共享存储区都有自己的名字。当进程间欲利用共享存储区进行通信时，必须先在主存中建立一共享存储区，然后将它**附接到自己的虚地址空间**上。此后，进程对该区的访问操作，与对其虚地址空间的其它部分的操作完全相同。为避免出错，各个进程对共享内存的访问必须是互斥的

- #### `工作原理`

1. **初始化：** 一个进程创建一个共享内存段，这个内存段对该进程是可见的，就像进程的私有内存一样。
2. **附加：** 其他进程可以将同一个共享内存段附加到自己的地址空间，使得这段内存变得对它们也是可访问的。
3. **使用：** 一旦共享内存被附加，进程就可以像访问自己的正常内存一样访问共享内存。进程可以读写存储在共享内存中的数据，就如同操作自己的局部变量一样。
4. **分离与销毁：** 进程使用完共享内存后，可以将其从自己的地址空间中分离。当所有使用它的进程都已分离，且不再需要该内存段时，可以将其销毁。

- #### `优点`

- **性能：** 由于不需要进程间发送消息或进行上下文切换，共享内存是最快的IPC方法。
- **灵活性：** 共享内存提供了一种灵活的方式，使得多个进程可以以任何所需的格式访问和修改数据。

- #### `缺点`

- **同步问题：** 使用共享内存时，必须仔细处理同步问题，以避免竞态条件和数据不一致。这通常需要使用信号量、互斥锁或其他同步机制。
- **复杂性：** 管理共享内存（分配、同步访问、清理）比使用其他IPC机制更加复杂。
- **安全与隔离：** 共享内存**破坏了进程间的内存隔离**，可能导致安全问题。



#### 5.9.2 消息传递（Message Passing）

****

- #### 基本概念

****

进程间的消息传递（Message Passing）是一种在计算机科学中广泛使用的通信机制，尤其是在并发编程和分布式系统中。这种机制允许进程之间**通过发送和接收消息来交换数据**，而不是直接共享内存。这样做有助于减少进程间的依赖性，增强系统的模块化，并有助于提高程序的可维护性和扩展性。

- #### `基本概念`

- **消息**：消息是在进程间传递的数据单元。消息可以是简单的如信号、数字，也可以是复杂的如数据结构或对象，信息的大小可以是固定的也可以是可变的
  - **固定大小：**系统级实现简单，但是编程非常困难，要考虑信息大小超过固定大小的情况
  - **可变大小：**系统级实现复杂，但是编程相对简单

- **发送和接收**操作

  ：进程使用发送操作将消息传递给另一个进程，并使用接收操作来接收其他进程发送的消息。发送和接收可以是同步的也可以是异步的。

  - **同步发送**（Synchronous Send）：发送进程在消息被接收之前被阻塞。
  - **异步发送**（Asynchronous Send）：发送进程在发送消息后可以继续执行，而不需要等待消息被接收。
  - **同步接收**（Synchronous Receive）：接收进程在接收到消息之前被阻塞。
  - **异步接收**（Asynchronous Receive）：接收进程可以继续执行，并在消息到达时被通知。

- #### `通信模型`

1. **直接通信**：在直接通信模型中，每个发送或接收操作都需要明确指定对方进程的标识符。这意味着发送进程需要知道接收进程的标识，反之亦然。

   - send (P, message)        //发送信息给进程P
   - receive (Q, message)   //从进程Q接收到信息

   链接是在每一对想要通信的进程之间自动创建的，进程只需要知道对方的标识符就能通信；链接只与特定的两个进程相关，对于每一对通信进程，一定存在一个链接；

2. **间接通信**：在间接通信模型中，消息是通过共享的数据结构（如**队列、主题或管道**）传递的，进程通过这些结构进行通信而不是直接引用对方，类似于每个进程都有一个“**邮箱**”可以查看信息。这种方式更加灵活，允许多个生产者和消费者之间的通信。

   - send (A, message)        //发送信息到邮箱A

   - receive (A, message)   //从邮箱A接收到信息

当两个进程都有同一个邮箱时建立链接，一个链接可以与多个进程相关，只要它们都有同样的邮箱就行。 进程可以有多个不同的邮箱所以可以有多个不同的链接，每个链接与邮箱绑定

**Example：**如果进程P1，P2，P3共享一个邮箱，当P1向邮箱发送一个信息，可以设计该信息只能被特定进程接收



****

- #### 管道 (Pipes)

****

管道主要有两种类型：

1. **匿名管道（Anonymous Pipes）**：
   - 仅能用于有共同祖先的进程间通信（如父子进程），因为它们没有与之关联的文件系统名字。
   - 一般用于单向通信——数据只能从一端流向另一端。
2. **命名管道（Named Pipes 或 FIFO）**：
   - 可以在没有共同祖先的任意进程之间进行通信，因为它们在文件系统中有一个名字。
   - 支持单向或双向通信。
   - 由于它们在文件系统中有一个明确的名字，所以不同的进程可以通过打开同一个命名管道来进行通信。

- #### `工作原理`

匿名管道的典型使用流程如下：

1. **创建管道**：进程调用`pipe()`系统调用创建一个管道，该调用返回两个文件描述符：一个用于读取（管道的读端），另一个用于写入（管道的写端）。
2. **使用管道**：创建管道后，原始进程通常会通过`fork()`系统调用创建一个子进程。父子进程中的一个将关闭读端描述符，另一个关闭写端描述符，这样就形成了一个单向通道。
3. **数据传输**：写端进程可以通过写端描述符向管道中写入数据，而读端进程则可以从读端描述符读取数据。**数据是按照写入的顺序被读取的。（先进先出）**
4. **关闭管道**：当通信完成后，进程会关闭相应的文件描述符。当管道的所有写端都被关闭后，读取操作会返回文件结束符（EOF），以示数据传输完成。

命名管道的使用流程与匿名管道类似，不同之处在于它首先需要通过`mkfifo()`系统调用（或类似的命令）在文件系统中创建一个管道文件，然后进程通过打开这个文件进行读写操作。

- #### `特点`

  - **简单性**：管道是一种简单的通信机制，容易实现和使用。

  - **单向数据流**：标准管道只支持单向数据流。如果需要双向通信，需要创建两个管道。

  - **数据的顺序性**：管道中的数据按照写入的顺序被读取。

  - **阻塞和非阻塞**：管道的读取和写入操作可以是阻塞的，也可以是非阻塞的，这取决于管道的配置和当前状态。

- #### `限制`

  - **缓冲区大小**：管道有一个**固定的**缓冲区大小（通常为几KB），当缓冲区满时，写操作会阻塞；当缓冲区空时，读操作会阻塞。

  - **生命周期和范围**：匿名管道的生命周期和可见范围通常限于创建它们的进程及其子进程。

  - **数据结构**：管道不适合传递复杂的数据结构，因为它们仅仅是字节流，没有内置的消息边界或结构化机制。

  

****

- #### 消息队列

****

- #### `工作原理`

  1. **创建消息队列**：一个进程会创建一个消息队列，并为它指定一个唯一的标识符或名称，其他进程可以使用这个标识符来访问队列。

  2. **发送消息**：进程可以将消息放入队列中。每个消息都可以被赋予一个特定的类型或优先级，以便接收方可以根据这些属性选择性地接收消息。

  3. **接收消息**：进程可以从队列中读取消息。接收操作可以是阻塞的，也可以是非阻塞的，并且接收方可以选择接收特定类型的消息。

  4. **管理队列**：系统或进程可以对消息队列进行查询、修改配置或删除队列等管理操作。

- #### `特点`

  - **解耦**：生产者和消费者之间不需要直接通信，它们只需要关注消息队列，这有助于降低系统组件之间的耦合度。

  - **异步通信**：消息队列允许进程继续执行而不需要等待消息的即时响应，有助于提高应用的吞吐量和响应性。

  - **持久性**：许多消息队列系统支持将消息持久化到磁盘，这意味着即使系统崩溃，消息也不会丢失。

  - **灵活性**：消息队列可以根据优先级、类型或其他属性来选择性地处理消息，提供了高度的灵活性。



#### 5.9.3 Socket

Socket通过IP地址和端口号来标识

服务器通过监听来等待传入的客户端请求，一旦收到请求，服务器就会接受来自客户端Socket的连接



- #### 信号量 (Semaphores）

主要用于同步，特别是控制对共享资源的访问。信号量可以是二进制的（也称为互斥锁）或可以有更高的值。



### 5.10 进程同步和互斥

![image-20240328220839973](Images\image-20240328220839973.png)

**同步：**

​	同步亦称直接制约关系，它是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上**协调**它们的**工作次序**而产生的制约关系。进程间的直接制约关系就是源于它们之间的相互合作。

****

![image-20240328221319043](Images\image-20240328221319043.png)

![image-20240328221506574](Images\image-20240328221506574.png)

![image-20240328223829592](Images\image-20240328223829592.png)

#### 5.10.1 进程互斥的软件实现方法

****

***单标志法***

****

**算法思想：**两个进程在**访问完临界区后**把使用临界区的权限转交给另一个进程。也就是说**每个进程进入临界区的权限只能被另一个进程赋予**

~~~c++
int turn = 0; //turn表示当前允许进入临界区的进程号 turn变量背后的逻辑：表达“谦让”
~~~

~~~c++
//P0进程
while(turn != 0);   //进入区
critical section;   //临界区
turn = 1;           //退出区
remainder section;  //剩余区

//P1进程
while(turn != 1);   //进入区
critical section;   //临界区
turn = 0;           //退出区
remainder section;  //剩余区
~~~

**问题：**只能按 P0→P1→P0 →P1→…这样轮流访问。这种必须“轮流访问”带来的问题是，如果此时允许进入临界区的进程是 P0，而 P0一直不访问临界区，那么虽然此时临界区空闲，但是并不允许P1访问。因此，**单标志法**存在的**主要问题**是：**违背“空闲让进”原则**



****

***双标志先检查法***

****

**算法思想：**设置一个布尔型数组flag，数组中各个元素用来**标记各进程想进入临界区的意愿**，比如“`flag[0]=ture`”意味着进程P0现在想要进入临界区。每个进程在进入临界区之前先检查当前有没有别的进程想进入临界区，如果没有，则把自身对应的标志flag[i]设为true，之后开始访问临界区

~~~c++
bool flag[2];            //表示进入临界区意愿的数组 背后的逻辑：“表达意愿”
flag[0] = false;
flag[1] = false;         //刚开始设置为两个进程都不想进入临界区
~~~

~~~c++
//P0进程
while(flag[1]);          //[1]如果此时P1想进入临界区，P0就一直循环等待
flag[0] = true;          //[2]标记P0进程想进入临界区
critical section;        //[3]访问临界区
flag[0] = false;         //[4]访问完临界区，修改标记为P0不想使用临界区
remainder section;

//P1进程
while(flag[0]);          //[5]如果此时P0想进入临界区，P1就一直循环等待
flag[1] = true;          //[6]标记P1进程想进入临界区
critical section;        //[7]访问临界区
flag[1] = false;         //[8]访问完临界区，修改标记为P1不想使用临界区
remainder section;
~~~

**问题：**并发执行可能会出问题。若按照 [1] [5] [2] [6] [3] [7]...的顺序执行，P0 和 P1将会同时访问临界区。因此，双标志先检查法的**主要问题**是:**违反“忙则等待”原则**。

**原因：进入区**的“检查”和“上锁”两个处理**不是一气呵成的**。“检查”后，“上锁”前可能发生进程切换。



****

***双标志后检查法***

****

**算法思想：**双标志先检查法的改版。前一个算法的问题是先“检查”后“上锁”，但是这两个操作又无法一气呵成，因此导致了两个进程同时进入临界区的问题。因此，人们又想到先“上锁”后“检查的方法，来避免上述问题。

~~~c++
bool flag[2];            //表示进入临界区意愿的数组 背后的逻辑：“表达意愿”
flag[0] = false;
flag[1] = false;         //刚开始设置为两个进程都不想进入临界区
~~~

~~~c++
//P0进程
flag[0] = true;          //[1]标记P0进程想进入临界区
while(flag[1]);          //[2]如果此时P1想进入临界区，P0就一直循环等待
critical section;        //[3]访问临界区
flag[0] = false;         //[4]访问完临界区，修改标记为P0不想使用临界区
remainder section;

//P1进程
flag[1] = true;          //[5]标记P1进程想进入临界区
while(flag[0]);          //[6]如果此时P0想进入临界区，P1就一直循环等待
critical section;        //[7]访问临界区
flag[1] = false;         //[8]访问完临界区，修改标记为P1不想使用临界区
remainder section;
~~~

**问题：**同样是并发执行会出现问题。若按照[1] [5] [2] [6]...的顺序执行，P0和P1将都无法进入临界区因此，双标志后检查法虽然**解决了“忙则等待”**的问题，但是**又违背了“空闲让进”和“有限等待“**原则，会因各进程都长期无法访问临界资源而**产生“饥饿”**现象。



****

***Peterson算法***

****

**算法思想：**结合双标志法、单标志法的思想。如果双方都争着想进入临界区，那可以让进程尝试“孔融让梨”(谦让)。做一个有礼貌的进程。

~~~c++
bool flag[2];            //表示进入临界区意愿的数组 背后的逻辑：“表达意愿”
int turn = 0;            //turn表示当前允许进入临界区的进程号 
~~~

~~~c++
//P0进程
flag[0] = true;          //[1] 表示自己想进入临界区
turn = 1;                //[2] 可以优先让对方进入临界区
while(flag[1]&& turn==1);//[3] 对方想进，且最后一次是自己“让梨”，那自己就循环等待
critical section;        //[4]
flag[0]= false;          //[5] 访问完临界区，表示自己已经不想访问临界区了
remainder section;

//P1进程
flag[1]= true;           //[6] 表示自己想进入临界区
turn = 0;                //[7] 可以优先让对方进入临界区
while(flag[0]&& turn==0);//[8] 对方想进，且最后一次是自己“让梨”，那自己就循环等待
critical section;        //[9]
flag[1]= false;          //[10]访问完临界区，表示自己已经不想访问临界区了
remainder section;
~~~

**”谁最后说了客气话，谁就失去了行动的优先权“**

**问题：**Peterson 算法用软件方法解决了进程互斥问题，**遵循了空闲让进、忙则等待、有限等待 三个原则**，但是依然**未遵循让权等待**的原则，出现“**忙等**”



#### 5.10.2 进程互斥的硬件实现方法

中断屏蔽方法，TS/TSL指令，Swap/XCHG指令



#### 5.10.3 自旋锁

像Peterson算法，中断屏蔽算法等需要忙等的算法用到的锁被称作自旋锁

- **特性：**需忙等，进程时间片用完才下处理机，**违反“让权等待”**
- **优点：**等待期间不用切换进程上下文，多处理器系统中，若上锁的时间短，则等待代价很低
- 常用于多处理器系统，一个核忙等，其他核照常工作，并快速释放临界区
- 不太适用于单处理机系统，根据算法的不同忙等的过程中可能一直等待导致系统崩溃
- 在多进程（线程）任务中，如果上下文切换的耗时大于忙等的耗时则应该采用自旋锁



### 5.11 信号量

为了解决**自旋锁无法实现“让权等待”**这一问题，Dijkstra提出了一种新的实现进程互斥、同步的方法——**信号量机制**

![image-20240328234947389](Images\image-20240328234947389.png)



#### 5.11.1 整型信号量

 **依旧会导致忙等**

![image-20240329000320537](Images\image-20240329000320537.png)

#### 5.11.2 记录型信号量

![image-20240329000637829](Images\image-20240329000637829.png)

想要访问计算机资源但是资源被占用的进程会被发送信号**从运行态变为阻塞态**，当其他占用该资源的进程释放该资源后会**查看记录**给因为等待该资源而进入阻塞态的进程发送信号**通知它们进入就绪态**



![image-20240329001416936](Images\image-20240329001416936.png)

![image-20240329001711890](Images\image-20240329001711890.png)



#### 5.11.3 信号量（互斥量）实现互斥（互斥锁）

**二元信号量也被称为互斥量**，可以用来创建互斥锁，**互斥锁相比自旋锁不会出现忙等待的问题**，必须对同一进程（线程）实现PV操作，必须成对出现，当某一进程无法获得资源时**会进入阻塞状态**

![image-20240329002348175](Images\image-20240329002348175.png)

#### 5.11.4 信号量实现同步

和互斥的区别就是**互斥操作是最开始的时候有资源**，**同步操作最开始的时候没资源**，要等先运行的程序执行完才会提供资源，**前V后P**

![image-20240329002900364](Images\image-20240329002900364.png)



#### 5.11.5 信号量实现前驱关系

**前驱关系问题本质就是多级同步问题**

![image-20240329003517081](Images\image-20240329003517081.png)

### 5.12 管程



### 5.13 死锁

#### 5.13.1 定义

**死锁：**在并发环境下，各进程（线程）因竞争资源而造成的一种**互相等待对方手里的资源，导致各进程都阻塞无法向前推进**的现象

![image-20240329014101606](Images\image-20240329014101606.png)

#### 5.13.2 进程死锁、饥饿、死循环的区别

**死锁：**各进程互相等待对方手里的资源，导致各进程都阻塞，无法向前推进的现象。

**饥饿：**由于长期得不到想要的资源，某进程无法向前推进的现象。比如:在短进程优先(SPF)算法中，若有源源不断的短进程到来，则长进程将一直得不到处理机，从而发生长进程“饥饿”

**死循环：**某进程执行过程中一直跳不出某个循环的现象。有时是因为程序逻辑 bug导致的，有时是程序员故意设计的。

![image-20240329014255044](Images\image-20240329014255044.png)

#### 5.13.3 产生的必要条件

![image-20240329022202796](Images\image-20240329022202796.png)

#### 5.13.4 为什么会发生死锁

![image-20240329022427970](Images\image-20240329022427970.png)



#### 5.13.5 处理策略-预防死锁

**简述：**破坏死锁的四个必要条件中的一个或几个

****

***破坏互斥条件***

****

![image-20240329023216289](Images\image-20240329023216289.png)

****

***破坏不可剥夺条件***

****

<img src="Images\image-20240329023505266.png" alt="image-20240329023505266"  />

****

***破坏请求和保持条件***

****

![image-20240329023726008](Images\image-20240329023726008.png)

****

***破坏循环等待条件***

****

![image-20240329024037452](Images\image-20240329024037452.png)



#### 5.13.6 处理策略-避免死锁（银行家算法）

**简述：**用某种方法防止系统进入不安全状态从而避免死锁（银行家算法）

****

**安全序列，不安全状态**

****

![image-20240329024419148](Images\image-20240329024419148.png)

**将30亿借给B会不安全，所以不能借**

![image-20240329024700817](Images\image-20240329024700817.png)

**将20亿借给A是安全的，可以借**



![image-20240329025035667](Images\image-20240329025035667.png)

****

***银行家算法***

****

**分配前判断会不会进入不安全状态**

![image-20240329025346658](Images\image-20240329025346658.png)

![image-20240329025535864](Images\image-20240329025535864.png)

**算法逻辑：**

![image-20240329030027085](Images\image-20240329030027085.png)

**安全性算法步骤：**

- 检查当前的剩余可用资源是否能满足某个进程的最大需求，如果可以，就把该进程加入安全序列，并把该进程持有的资源全部回收。
- 不断重复上述过程，看最终是否能让所有进程都加入安全序列。



#### 5.13.7 处理策略-检测和解除

**简述：**允许死锁发生，不过操作系统会负责检测出死锁的发生，然后采取某些措施解除死锁

需要两种算法：**死锁检测算法和死锁解除算法**



## 6. 线程

线程是进程内的执行单元，一个进程可以有多个线程，线程还是CPU调度的最小单元 

### 6.1 线程状态

线程也有**类似于进程的状态**，这些状态描述了线程在其生命周期中的不同阶段。线程作为轻量级的执行单元，共享进程的资源如代码段，内存和文件句柄，但它们拥有自己的执行上下文，包括**程序计数器、寄存器集和栈**。线程的状态管理对于多线程程序的性能和资源利用至关重要。

1. **新建（New）**：线程已经被创建，但尚未开始执行。在这个状态下，线程的资源和执行上下文已经准备好，等待被线程调度器选中分配CPU时间。
2. **就绪（Runnable/Ready）**：线程准备好执行，等待获取CPU时间。就绪状态的线程位于线程调度器的就绪队列中，一旦调度器选择了某个线程，它就会转移到运行状态。
3. **运行（Running）**：线程正在CPU上执行。线程从就绪状态转移到运行状态后，会执行其任务直到完成，或者因某些原因被迫暂停。
4. **阻塞（Blocked）/等待（Waiting）**：线程由于某些原因无法继续执行，进入等待状态，直到某个事件发生。这可能是因为I/O操作、获取同步锁失败或其他等待资源。阻塞状态的线程不会消耗CPU资源，它们在等待事件完成后会转移到就绪状态。
5. **超时等待（Timed Waiting）**：允许线程在指定的时间内等待某个条件的发生。如果条件在超时时间内得到满足，线程会继续执行；如果超时时间到达而条件仍未满足，线程可以选择继续等待、重试或执行其他操作。这种机制对于避免线程永久阻塞在某个条件上非常有用，特别是在条件可能因为外部因素而长时间不满足的情况下。
6. **终止（Terminated）**：线程的执行已经完成或者被强制终止。一旦线程终止，它所占用的所有资源将被释放，线程对象变为不可再用。



### 6.2 TCB(Thread Control Block)

TCB（Thread Control Block）是操作系统中用于存储线程信息的数据结构。它包含了管理和调度线程所需的所有关键信息。每个线程都有一个与之对应的TCB，操作系统通过TCB来控制线程的执行，包括线程的创建、暂停、恢复和终止等。

进程控制块（PCB）或与之类似的结构会**包含指向其内部每个线程TCB的指针**，以便操作系统可以管理和调度这些线程。

- ### TCB 包含的主要信息：

1. **线程标识符**：唯一标识每个线程的信息，通常包括线程ID等。
2. **线程状态**：表示线程当前的执行状态，如就绪（Ready）、运行（Running）、等待（Waiting）、终止（Terminated）等。
3. **程序计数器（PC）**：存储线程下一条要执行指令的地址。它指示了线程在其执行代码中的当前位置。
4. **寄存器集**：保存线程当前执行上下文的处理器寄存器的值，包括累加器、索引寄存器、栈指针和基指针等。
5. **堆栈指针**：指向线程私有栈的顶部。线程栈用于存储局部变量、返回地址和函数调用的历史。
6. **线程优先级**：用于调度决策，表示线程的执行优先级。在多线程调度中，通常优先级高的线程会被优先调度执行。
7. **线程特定的存储区**：用于存储线程局部存储（TLS）的数据，这些数据对其他线程不可见。
8. **信号掩码**：定义了线程对哪些信号的响应方式，即哪些信号被阻塞，哪些信号可被线程接收。
9. **上下文信息**：包括线程的寄存器集、程序计数器和堆栈指针，足够在线程被重新调度运行时恢复其执行状态。
10. **资源指针**：指向线程所使用的各种资源，如文件描述符、打开的文件句柄、分配的内存区域等。

### 6.3 线程共享内容

****

- #### **内存空间**

****

- **代码段**：所有线程共享同一进程的代码段，意味着它们**执行相同的程序代码**。
- **数据段**：包括全局变量和静态变量，这部分内存也被进程内的所有线程共享。
- **堆**：动态分配的内存（如C/C++中的`malloc`或`new`分配的内存，Java中的对象）位于堆区，这也是由进程的所有线程共享的。

****

- #### 操作系统资源

****

- **文件描述符**：打开的文件、管道、套接字等由进程管理，因此它们在同一进程的所有线程之间共享。
- **信号和信号处理程序**：信号是一种进程级别的通信机制，信号及其处理函数对同一进程下的所有线程都是可见和共享的。

****

- #### 进程属性

****

- **环境变量**：进程的环境变量设置对所有线程都是共享的。
- **当前目录**：进程的工作目录是共享的，对文件系统的相对路径操作会影响到同一进程内的所有线程。

****

- #### 系统资源

****

- **进程ID**：虽然每个线程有自己的线程ID，但它们共享相同的进程ID。
- **父进程ID**：与进程ID相同，所有线程都能访问相同的父进程ID。
- **进程的用户ID和组ID**：对操作系统资源的访问权限由进程的用户ID和组ID控制，这对进程内的所有线程都是一样的。



### 6.4 线程独占内容

- ###  **线程栈**

每个线程拥有自己的栈空间，用于存储函数调用时的局部变量、函数参数、返回地址和栈帧等。这个独立的栈空间是线程执行函数调用的基础，确保了线程函数调用的独立性和安全性。

- ### **线程上下文（寄存器状态）**

线程的上下文包括程序计数器（PC）、堆栈指针和其他处理器寄存器的状态。这些寄存器保存了线程当前执行状态的信息，包括当前执行指令的位置（PC）、局部变量和函数参数的地址（堆栈指针）等。当线程被操作系统挂起时，它的上下文会被保存，以便线程恢复执行时可以从中断点继续。

- ###  **线程局部存储（TLS）**

线程局部存储是一种允许数据在多个线程中有各自独立实例的机制。每个线程访问TLS变量时，实际上访问的是自己独有的数据副本。这对于保持线程的状态信息、避免全局变量的共享使用非常有用。

- ### **线程ID**

每个线程有一个唯一的线程ID，用于标识和管理线程。虽然线程ID本身可以被进程中的其他线程访问，但每个ID唯一对应一个线程，因此可以视为线程的“独占资源”。

- ### **线程的信号屏蔽**

在某些操作系统中，线程可以屏蔽（忽略）或处理特定的信号。这些信号屏蔽状态是线程特有的，不同线程可以有不同的信号屏蔽配置。

- ### 线程的优先级和调度策略

线程的优先级和调度策略决定了线程相对于进程中其他线程的执行优先级。这些属性可以被视为线程独占的，因为它们影响的是线程自身的调度和执行。



### 6.5 多线程的优点

- ###  **并发执行**

多线程允许程序同时执行多个任务。这可以显著提高应用程序的吞吐量和效率，尤其是在多核处理器上，不同的线程可以在不同的核上并行运行。

- ### **资源共享**

线程共享其父进程的内存空间和资源，这使得线程间的数据共享变得容易和高效。与进程相比，线程间的通信成本更低，因为它们可以直接访问相同的内存空间。

- ### **响应性**

在一些需要快速响应用户输入或其他事件的应用中，多线程可以在一个线程等待或执行长时间操作时，保持应用的响应性。例如，图形用户界面（GUI）应用程序通常在一个单独的线程中处理用户界面事件，以保持界面响应用户操作。

- ### **更好的系统资源利用**

多线程允许应用程序在等待I/O操作（如读取文件或网络通信）完成时继续执行其他任务。这种I/O并发可以显著提高应用程序对系统资源的利用率。

- ### **更简洁的异步编程模型**

在处理异步操作时，多线程提供了一种比事件驱动或回调更直观、更易于理解和管理的编程模型。通过线程，可以将异步操作表达为顺序代码，这简化了编程模型，减少了代码复杂性。

- ### **分离复杂任务**

复杂或耗时的任务可以分解为多个线程，每个线程处理任务的一部分。这不仅可以提高任务的执行速度（通过并行处理），还可以使代码组织更清晰，每个线程可以专注于执行一个具体的子任务。

- ### **优化多核处理器性能**

现代计算机系统通常配备有多核处理器。多线程使得应用程序能够通过在多个核心上并行执行线程来充分利用这些处理器资源，从而提高整体性能。



### 6.6 多线程和多子进程的对比

开启多个子进程可以在某种程度上达到类似多线程的效果，特别是在**并行处理和任务分解**方面。然而，进程与线程之间存在本质区别，这些区别导致它们在应用程序设计和性能方面具有不同的特点和考虑事项。

- ### 相似之处

1. **并行性**：无论是多线程还是多进程，都可以利用多核CPU的能力，通过并行执行来提高程序的执行效率。
2. **任务分解**：复杂或耗时的任务可以在多个线程或进程之间分解，实现任务的并发执行。

- ### 不同之处

1. **资源共享与隔离**：
   - **线程**：线程共享其父进程的内存空间和资源，如代码段、数据段和打开的文件等。这使得**线程间的通信和数据共享更为高效**，但也需要额外的同步机制来避免竞态条件。
   - **进程**：每个进程拥有独立的内存空间和资源。这种隔离提高了进程间的安全性和稳定性，但使得进程间的通信更为复杂，通常需要使用进程间通信（IPC）机制，如管道、消息队列、共享内存等。
2. **开销**：
   - **线程**：**线程的创建、切换和销毁的开销通常小于进程**，因为线程共享大部分进程资源。
   - **进程**：每个进程都有独立的地址空间，创建和切换进程的开销通常大于线程。此外，进程间的通信开销也大于线程间的通信。
3. **容错性与隔离**：
   - **线程**：线程间共享相同的地址空间，一个线程的崩溃可能影响到同一进程内的其他线程。
   - **进程**：进程间彼此隔离，一个进程的崩溃不会直接影响到其他进程。

- ### 使用场景

- **多线程**：适用于高度并发、需要大量数据共享和通信的应用场景，如服务器应用、复杂的计算任务等。
- **多进程**：适用于需要高度隔离、稳定性更重要的场景，或者是需要运行不同程序的情况，**如浏览器的每个标签页运行在独立进程中**，以提高整体应用的稳定性和安全性。



### 6.7 多线程模型

#### 6.7.1 用户级线程

![image-20240328185823875](Images\image-20240328185823875.png)

操作系统**看不到用户级线程**，用户级线程可以理解为用户用**线程库**在逻辑上模拟了线程的功能，也因此当用户级线程阻塞时操作系统无能为力，也因为用户级线程是模拟了线程的功能，所以用户级线程的管理由应用程序的线程库来负责，**不需要切换到内核态**



- **优点：**

​	用户级线程的切换在用户空间即可完成，不需要切换到内核态，效率更高；

- **缺点：**

​	当一个用户级线程被阻塞后，整个进程都会被阻塞，并发度不高。多个线程不可在多核处理机上并行运行；



#### 6.7.2 内核级线程

![image-20240328191052348](Images\image-20240328191052348.png)



#### 6.7.3 一对一模型

![image-20240328191234494](Images\image-20240328191234494.png)

#### 6.7.4 多对一模型

**退化**为了纯用户级线程

![image-20240328191338916](Images\image-20240328191338916.png)



#### 6.7.5 多对多模型

![image-20240328191846426](Images\image-20240328191846426.png)



## 7. 内存

### 7.1 内存管理

- 操作系统负责**内存空间的分配和回收**；
- 操作系统需要提供某种技术从逻辑上**对内存空间进行扩充（虚拟地址）**；
- 操作系统需要提供地址转换功能，负责程序的**逻辑地址**和**物理地址**的转换；

![image-20240329033719898](Images\image-20240329033719898.png)

- 操作系统要负责**进程保护**，防止进程访问越界

![image-20240329034006584](Images\image-20240329034006584.png)

# 常见问题

## 1. 同步，异步，阻塞，非阻塞

[深入理解同步阻塞、同步非阻塞、异步阻塞、异步非阻塞_同步阻塞 同步非阻塞 异步阻塞 异步非阻塞-CSDN博客](https://blog.csdn.net/wangpaiblog/article/details/117236684#:~:text=同步阻塞：在需要某资源时马上发起请求，并暂停本线程之后的程序，直至获得所需的资源。 同步非阻塞：在需要某资源时马上发起请求，且可以马上得到答复，然后继续执行之后的程序。,但如果得到的不是完整的资源，之后将周期性地的请求，直至获得所需的资源。 异步阻塞：在需要某资源时不马上发起请求，而安排一个以后的时间再发起请求。)

**同步：**指现在在做某件事，但是突然有另一件事需要做，于是我立刻去做另一件事

**异步：**指现在在做某件事，但是突然有另一件事需要做，可是我不急，等会再去做另一件事，现在先继续做之前的事

**阻塞：**我去做另一件事了，在拿到结果前我什么也不做

**非阻塞：**我去做另一件事了，在等待结果时继续做别的事，时不时看看结果出没出来

简单总结就是同步异步**关心的是某件事要不要立刻做**，阻塞非阻塞关心的是**开始做某事了我要不要在那干等结果不干别的**



- **同步阻塞：**在需要某资源时马上发起请求，并暂停本线程之后的程序，直至获得所需的资源。
- **同步非阻塞：**在需要某资源时马上发起请求，且可以马上得到答复，然后继续执行之后的程序。但如果得到的不是完整的资源，之后将周期性地的请求，直至获得所需的资源。
- **异步阻塞：**在需要某资源时不马上发起请求，而安排一个以后的时间再发起请求。当到了那时发出请求时，将暂停本线程之后的程序，直至获得所需的资源。在获取资源之后，使用共享信号量、异步回调等方式将结果异步反馈。
- **异步非阻塞：**在需要某资源时不马上发起请求，而安排一个以后的时间再发起请求。当到了那时发出请求时，可以马上得到答复，然后继续执行之后的程序。但如果得到的不是完整的资源，之后将周期性地的请求。在最终获取到资源之后，使用共享信号量、异步回调等方式将结果异步反馈。



## 2. 互斥锁，自旋锁和读写锁的区别

- **互斥锁（Mutex）：**互斥锁使用到了互斥量（二元信号量），其保证在任意时刻只有一个线程能够进入被保护的临界区。当一个线程获取到互斥锁后，其他线程若要进入临界区会被阻塞，直到该线程释放锁。互斥锁是一种阻塞锁，当线程无法获取到锁时，会进入阻塞状态。使用互斥锁需要**成对使用PV操作**，如果**只使用P操作会导致资源无法释放**，如果**只使用V操作会导致无法实现互斥访问临界资源**
- **自旋锁（Spinlock）：**自旋锁是一种忙等待锁，当一个线程发现自旋锁被其他线程占用时，它会一直循环等待而不进入阻塞状态，直到该自旋锁可用。自旋锁是一种非阻塞锁，线程在等待锁期间会一直占用 CPU 资源进行循环检测。**自旋锁可以是抢占式或非抢占式的**，要注意非抢占式自旋锁根据使用算法的不同可能无法用在单处理机系统中
- **读写锁（ReadWrite Lock）：**读写锁允许多个线程同时对共享数据进行读操作，但只允许单个线程进行写操作。当有线程正在写入时，其他线程无法进行读操作，防止数据不一致性。读写锁允许多个线程并发读，但只能允许单个线程进行写操作。写操作时需要独占锁，阻塞其他线程的读写操作。

应用场景上，
互斥锁适用于临界区资源访问时间较长或存在阻塞操作的情况
自旋锁适用于临界区资源访问时间短，且线程竞争不激烈的情况
读写锁适用于读操作远远多于写操作的场景，可以提高并发读性能